Automatic terminology extraction, so the computer find relevant terminology in large text corpora (single - or multi language), one of the labour and thus expensive processes in terminology work can help enormously. However, the tools available are still far away from perfection. You place their emphasis often on yield and not on precision: be found to all candidates, even if in many not-Termini with collected. This leads to an enormously expensive part manual post-processing. The aim of the project was to reduce this burden. For this purpose, 4 heuristics have been programmed (Perl script), which filter the term candidates extracted from the examined system automatically and automatically mark non-Termini. Allowing their use showed a reduction of unwanted candidates around 30%; real terms were marked it only occasionally unintentionally. Short real terms have rarely long target language equivalents and vice versa: a heuristic, which eliminated the term candidate pairs proved particularly influential therefore, where output language and target linguistic expression more than 10 characters differ. Total tested heuristics proved a more promising approach, increasing the precision in the bilingual term extraction. The project was completed in 2002.
