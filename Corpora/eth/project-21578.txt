  Integrated, automated processing of terrestrial laser and digital image data for object recognition, 3D modelling, co-registration of point clouds and image orientation 
In this project it is attempted to orient arbitrarily taken images to a point cloud without intensities semi-automatically.
Terrestrial laser scanners and digital cameras are increasingly used the last 10 years, in a continuously growing number of applications for cultural heritage, geomatics, industry and manufacturing to medicine. Many applications have the goal to generate high-quality geometric and texture models. The processing of the resulting large datasets with billions of points is time-consuming, cumbersome and not automated enough. Thus, our goals are to develop accurate, reliable, fast and automated processing methods, in order to facilitate a wider usage of these sensors and establish new applications. This SNF project uses as input data single or multiple laser scans and digital images taken from arbitrary positions with respect to the laser scanner stations in order to optimize image acquisition conditions for high-quality texturing. It is assumed that for the laser scanning well-defined control and tie objects (e.g. spheres) have been mounted in the scene, while for the digital images no control information is provided. The project consists of two Parts, A and B. In Part A, we aim at the automated orientation of optical images with respect to each other by extracting and matching image features (mainly points). After a robust adjustment to eliminate matching errors, the relative image orientation is computed and a very dense photogrammetric point cloud is extracted via matching. To co-register the laser and photogrammetric point clouds different strategies will be combined. A 3D matching of the two point clouds, matching between digital images and scanner intensity, as well as matching of characteristic 2D/3D features, like planes and edges. After co-registration a combination of the two point clouds can lead to several advantages: increase of the density and accuracy of the points, coverage of missing areas (holes, occlusions, elevated areas that could not be scanned), improved modelling of edges and corners (which are well-defined in the images but not in the laser data), easier detection of blunders, modelling of areas where the laser penetrates the target object (e.g. different types of marble) and more accurate texturing of the geometric model. In Part B, we aim at the automatic detection, recognition and modelling of certain, mathematically well-defined basic features and objects. The basic features include planes and edges, the objects are limited to spheres, cones and cylinders, although they could optionally be extended to other objects. For the recognition, we use range and intensity images which are generated from the raw laser data without information loss. These two images allow easier and faster 2D processing compared to traditional 3D approaches, in particular because standard image processing techniques can be used. If available, our approach will use prior knowledge about target objects such c ETH Zürich, all rights reserved. Last updated: 06.08.2004 <page 2> as their shape, size, material, reflectance characteristics, number and approximate 3D position. Depending on the application, we may use additional knowledge (e.g. cylindrical pipes run horizontally or vertically) as well as constraints for features such as planes and edges to be orthogonal, parallel, horizontal or vertical. We also generate pre-knowledge regarding the range and intensity appearances of the defined objects in these two types of images with lab tests at various distances. Thus, templates are generated which will be used for recognition of the objects in the images via a least squares template matching. The recognition of the objects will be performed for each scan separately. Based on our approach for automated registration of multiple scans, all 3D laser points from different scanner stations that have been recognized as belonging to a target object will be combined to model the object with a robust adjustment technique. The automated recognition of objects can be used for registration of laser point clouds, georeferencing and 3D object modelling, preferably of anthropogenic, well-structured environments. We will use synergies between the two project parts, whereby results from one will be used to guide processes in the other, while at various processing stages and at the very end, the results will be combined and fused leading to higher automation, reliability and quality of 3D models. Extensive practical tests will be carried out. Building facades of small and medium complexity will be used for modelling by both parts. In Part B we will cooperate with the Geomatics Authority of Zurich City for modelling of sewage caverns. We expect that the proposed project will strongly enhance the applicability and ease the use of these technologies in various applications and will increase the body of scientific knowledge. Furthermore, we envisage exploitation of the results in cooperation with related manufacturers of hardware and software.