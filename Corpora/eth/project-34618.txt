  Identification via the Broadcast Channel  
We study the identification capacity of the broadcast channel with two outputs. Put differently, we want to know how large the number of receiving parties at each channel output can be if the encoder wants to address two receiving parties, namely one at each output,  with vanishing error probability.
Description: In Shannon's classical transmission problem, the encoder transmits a message from a set of size M over a discrete memoryless channel (DMC), and the receiver guesses the transmitted message from the channel outputs. The guess can be any of the M messages, and the receiver thus faces a hypothesis-testing problem with M hypotheses. Ahlswede and Dueck's identification-via-channels problem is different. Here the encoder sends an identification (ID) message from a set of size M, and M receiving parties observe the channel outputs. Each party is focused on a different message m. The m-focused party guesses whether or not Message m was sent. It thus faces a hypothesistesting problem with only two hypotheses. While in Shannon's problem the number of messages that can be transmitted reliably is exponential, and the transmission rate is defined as the logarithm of the number of transmission messages normalized by the blocklength n, in the ID problem the number of messages that can be identified reliably is double exponential, and the ID rate is defined as the iterated logarithm of the number of ID messages normalized by n. The supremum of all achievable rates is the same for the two problems: both the transmission and the ID capacity equal the maximum mutual information between the channel input and output, where the maximum is over all input distributions. Here we study identification via the broadcast channel (BC) W(y,z|x), where the sender wishes to simultaneously send one distinct ID message to each receiver. Preliminary Results: We proved that under the average error criterion, which requires that each receiver reliably identify its message if the other receiver's message is uniformly distributed, the identification (ID) capacity of the two-receivers broadcast channel is the set of rate pairs satisfying that, for some distribution on the input, each receiver's ID rate does not exceed the mutual information between the input and the output that it observes. Moreover, we showed that the capacity's interior is achieved by codes with deterministic encoders. Key in the proof is a new ID code for the single-user channel, which we designed. Discussion: For the classical transmission problem on the BC, the capacity does not depend on the error criterion: the capacities under the maximum and the average error criterion are the same. Our results indicate that for the identification problem on the BC, the error criterion makes a difference. c ETH Zürich, all rights reserved. Last updated: 06.08.2004 <page 2> Our results show that the interference between the messages for the two outputs of the BC is much smaller in the identification problem than in the transmission problem. Relevant Literature: IEEE Trans. Inf. Theory, IT-35, No. R. Ahlswede and G. Dueck, TIdentification via channels,T 1, pp. 15U29, Jan. 1989. mathematical theory of communication,T The Bell System Tech. J., Vol. 27, C. E. Shannon, TA pp. 379U423 and 623U656, July and Oct. 1948. IEEE Trans. T. S. Han and S. Verdt'u, TNew results in the theory of identification via channels,T Inf. Theory, IT-38, No. 1, pp. 14U25, Jan. 1992. B. Verboven and E. C. van der Meulen, TCapacity bounds for identification via broadcast channels IEEE Trans. Inf. Theory, IT-36, No. 6, that are optimal for the determination broadcast channel,T pp. 1197U1205, Nov. 1990. I. Bilik and Y. Steinberg, TInner and outer bounds on the identification capacity region of the degraded broadcast channel,T Proc. of IEEE Int. Symp. on Inf. Theory (ISIT), pp. 146U146, June 2001. Y. Oohama, TConverse coding theorem for identification via general degraded broadcast chan Proc. of IEEE Int. Symp. on Inf. Theory (ISIT), p. 226, July 2003. nels,T Discrete Applied Mathematics, R. Ahlswede, TGeneral theory of information transfer: updated,T Vol. 156, No. 9, pp. 1348U1388, May 2008. R. Ahlswede and G. Dueck, TIdentification in the presence of feedbacka discovery of new ca pacity formulas,T IEEE Trans. Inf. Theory, IT-35, No. 1, pp. 30U36, Jan. 1989. IEEE Trans. Inf. TheoT. S. Han and S. Verdt'u, TApproximation theory of output statistics,T ry, IT-39, No. 3, pp. 752U772, May 1993.