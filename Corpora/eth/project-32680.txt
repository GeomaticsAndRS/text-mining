  Detailed Real-World Shape Reconstruction of Reflective Surfaces and Objects  
The goal is to improve the geometrical understanding of the behavior of reflective surfaces, with respect to useful and practical approximations when observing. We want to focus not only on the rough shape of the object, but on the details and subtle changes in surface  normal dominating reflections.
In the field of computer vision, graphics and surveying substantial progress has been made over the last years in developing techniques for capturing 3D models [Debevec et al. 1996; Levoy et al. 2000; Pollefeys et al. 2004; Newcombe et al. 2011] and measuring surface properties [Marschner et al. 2000; Dana et al. 1999; Chen et al. 2002] to generate faithful copies of the real-world. For instance, there has recently been a lot of interest in capturing visual models of cities [Frueh and Zakhor 2004; Pollefeys et al. 2008; Xiao et al. 2009; Nan et al. 2010] but it is clearly also desirable to reconstruct objects such as cars or scan industrial installations, glossy furniture at home, smart phones or windows. However, existing capturing techniques struggle with reflective scenes and objects as these do not reflect sufficient laser-light back to a range sensor or due to their reflective nature violating the Lambertian assumption underlying most image-based techniques. Consequently, resulting 3D models contain holes or erroneous data wherever reflection occurs and have to be post-processed after capturing. Typically, this would remove gross errors or close holes in bigger models but for the reflective parts themselves, no practical techniques exist to capture them in real-world settings. The goal of this research effort is to improve the geometrical understanding of the behavior of reflective surfaces, in particular with respect to useful and practical approximations when observing. In particular we want to focus not only on the rough shape of the object (almost flat glass, but on the details and subtle changes in surface normal (due to design, cylindrical cooking pot, E) imperfections in manufacturing or tension) that dominate the reflection of the scenery. Based on these insights, we plan to develop techniques that allow to scan such reflective surfaces by means of standard cameras in real-world scenarios and then to infer their shape with very high detail. Earlier works for reconstructing reflective surfaces proposed scanning techniques in controlled lab environments based on well-known calibration targets. In contrast, the proposed line of research for this project is to extend the successful idea of structure-from-motion in unknown environments to reflective scenarios. This means that no artificial calibration targets will be placed into the scene but the existing scenery should be exploited in all steps to reconstruct the surface/object when a camera films the object or a survey car passes through a street with reflective facades. The steps to achieve this can be categorized roughly as 1) estimation of camera ego-motion in reflective settings, 2) tracking of reflections on the surface (or specular flow), 3) estimation of what is being reflected and 4) estimation of surface normal maps/geometry. Finally, a reflective bundle adjustment (joint optimization of all camera and scene parameters) would improve a solution. All four problems will be addressed in this project and for all of them practical solutions are either limited to very restricted scenarios (lab conditions) or do not exist nowadays such that each step will mean substantial scientific progress towards automatic 3D scene understanding. Practically, the developed methodology would allow to faithfully reconstruct reflective surfaces and objects for planning, visualization, and simulation, where nowadays models look artificial (e.g. houses with perfect mirrors as windows), require a huge amount of manual interaction (somebody adding the windows manually to the scan/model) or simply cannot be obtained in real-world situations. Second, the developed techniques have the potential for a much broader impact, e.g. they could enable automated quality control processes in manufacturing and civil engineering, to scan c ETH Zürich, all rights reserved. Last updated: 06.08.2004 <page 2> ´ for defects or to detect stress or pressure visible through subtle deformations of the materialSs normals, and finally might even be deployed to autonomous cars or other robotic vehicles to be able to interact in or scan more complex environments. Equipment used : Hand-handled camera, video-cameras, computers and Graphical Processing Units